################################################################################
# COPY AND PASTE THIS INTO JUPYTER TERMINAL
# Access Jupyter at: http://70.77.113.32:40967
# Token: 777a532aaf0986352cc05212a1758cba60eb709b76fd4707d556c1cb6ffb864a
################################################################################

# Complete one-line setup and download command:

cd /workspace && pip3 install --quiet kaggle && mkdir -p datasets/{tier1,tier2,tier3} models logs && mkdir -p ~/.kaggle && echo '{"username":"issadalu","key":"5aabafacbfdefea1bf4f2171d98cc52b"}' > ~/.kaggle/kaggle.json && chmod 600 ~/.kaggle/kaggle.json && cat > download.py <<'EOF'
import subprocess, os, json
from pathlib import Path
from datetime import datetime

datasets = [
    ('vulamnguyen/rwf2000', 'tier1/RWF2000', 'RWF-2000', 2000, 1.5),
    ('odins0n/ucf-crime-dataset', 'tier1/UCF_Crime', 'UCF-Crime', 1900, 12.0),
    ('toluwaniaremu/smartcity-cctv-violence-detection-dataset-scvd', 'tier1/SCVD', 'SmartCity-CCTV', 4000, 3.5),
    ('mohamedmustafa/real-life-violence-situations-dataset', 'tier1/RealLife', 'Real-Life Violence', 2000, 2.0),
    ('arnab91/eavdd-violence', 'tier1/EAVDD', 'EAVDD', 1500, 1.8),
]

print("="*80)
print("NexaraVision Dataset Download - Starting")
print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*80)

results = []
for i, (kid, path, name, vids, size) in enumerate(datasets, 1):
    print(f"\n{'='*80}\n[{i}/{len(datasets)}] {name} ({vids:,} videos, {size}GB)\n{'='*80}")
    out = Path(f"/workspace/datasets/{path}")
    out.mkdir(parents=True, exist_ok=True)
    try:
        start = datetime.now()
        subprocess.run(['kaggle', 'datasets', 'download', '-d', kid, '-p', str(out), '--unzip'], check=True, timeout=3600)
        vcnt = sum(len(list(out.rglob(f'*.{ext}'))) for ext in ['mp4','avi','mkv','webm','mov'])
        sz = sum(f.stat().st_size for f in out.rglob('*') if f.is_file()) / (1024**3)
        elapsed = (datetime.now() - start).total_seconds()
        print(f"âœ… SUCCESS: {vcnt:,} videos, {sz:.2f}GB, {elapsed:.1f}s")
        results.append({'name': name, 'status': 'success', 'videos': vcnt, 'size_gb': round(sz,2), 'time_s': round(elapsed,1)})
    except Exception as e:
        print(f"âŒ FAILED: {str(e)[:200]}")
        results.append({'name': name, 'status': 'failed', 'error': str(e)[:200]})

with open('/workspace/datasets/results.json', 'w') as f:
    json.dump({'timestamp': datetime.now().isoformat(), 'results': results}, f, indent=2)

successful = [r for r in results if r['status'] == 'success']
print(f"\n{'='*80}\nðŸ“Š SUMMARY\n{'='*80}")
print(f"âœ… Success: {len(successful)}/{len(results)}")
print(f"ðŸ“¹ Total Videos: {sum(r.get('videos',0) for r in successful):,}")
print(f"ðŸ’¾ Total Size: {sum(r.get('size_gb',0) for r in successful):.2f}GB")
print(f"â±ï¸  Total Time: {sum(r.get('time_s',0) for r in successful)/60:.1f} min")
os.system("du -sh /workspace/datasets")
print("="*80)
EOF
python3 download.py

################################################################################
# After pasting the above, the download will start automatically
# Expected time: 10-30 minutes for all 5 datasets (11,400 videos, ~21GB)
################################################################################
