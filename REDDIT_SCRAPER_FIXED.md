# Reddit Scraper - Fixed Version

## What Was Wrong

Your initial run showed:
```
âœ… Found 50 videos initially
âŒ Then stopped finding new content (0/20 scrolls with no new)
```

**Root Cause**: Reddit's infinite scroll wasn't triggering because we were scrolling small increments (300-800px) instead of reaching the bottom where Reddit loads more content.

## What I Fixed

### Change 1: Scroll to Bottom (Line 44)
```python
# OLD: Small incremental scrolls
scroll_distance = random.randint(300, 800)
await page.evaluate(f"window.scrollBy(0, {scroll_distance})")

# NEW: Scroll to absolute bottom to trigger Reddit's loader
await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
```

### Change 2: Wait for Content Load (Line 307)
```python
await self.human_like_scroll(page)

# Wait 2 seconds for new content to load
await page.wait_for_timeout(2000)
```

## How Reddit Infinite Scroll Works

1. User scrolls near bottom of page
2. Reddit detects scroll position
3. Reddit loads next batch of ~25-50 posts
4. New content appears at bottom
5. Repeat

**Key**: Must reach `document.body.scrollHeight` (bottom) to trigger load

## Test the Fixed Version

```bash
cd /workspace/violence_detection_mvp

# Kill stopped process
fg
# Press Ctrl+C to kill it

# Run updated script
python3 scrape_reddit_infinite_scroll.py
```

**Expected Output**:
```
ðŸš€ Starting Reddit scraper...
ðŸ“Š Target: 10000 videos or 180 minutes

ðŸ” DEBUG: Page Structure
   /comments/ links: 100

ðŸ“¹ Found 50 new videos | Total: 50 | Runtime: 0.2min
ðŸ“¹ Found 23 new videos | Total: 73 | Runtime: 0.5min    â† NEW! Finding more
ðŸ“¹ Found 31 new videos | Total: 104 | Runtime: 0.8min   â† Continuous loading
ðŸ“¹ Found 27 new videos | Total: 131 | Runtime: 1.1min
ðŸ’¤ Taking a short break...
ðŸ“¹ Found 19 new videos | Total: 150 | Runtime: 1.5min
...
```

## Why This Works

**Reddit's Infinite Scroll Trigger**:
- Monitors `window.scrollY + window.innerHeight >= document.body.scrollHeight - 500`
- When scroll position is within 500px of bottom â†’ load more
- Our fix: Scroll directly to `scrollHeight` â†’ guaranteed trigger

**With Random Delays**:
- 2-5 second delays between scrolls (human-like)
- Occasional 3-8 second "reading" pauses (30% chance)
- 10-20 second breaks every 10 scrolls
- Result: ~20-30 videos/minute (1,200-1,800 videos/hour)

## Expected Timeline

```
Hour 0-6:   Collect 7,000-10,000 URLs âœ…
Hour 6-54:  Download 6,000-8,000 videos
Hour 54:    Ready for training ðŸŽ¯
```

## If Still Not Working

Run this debug version to see what's happening:

```bash
python3 << 'EOF'
import asyncio
from playwright.async_api import async_playwright

async def debug_reddit():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)  # Visible
        page = await browser.new_page()

        await page.goto("https://www.reddit.com/search/?q=fights&type=media")
        await asyncio.sleep(5)

        # Get initial count
        initial = await page.evaluate('document.querySelectorAll("a[href*=\\"/comments/\\"]").length')
        print(f"Initial links: {initial}")

        # Scroll to bottom
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        await asyncio.sleep(3)

        # Get new count
        after = await page.evaluate('document.querySelectorAll("a[href*=\\"/comments/\\"]").length')
        print(f"After scroll: {after}")
        print(f"Difference: {after - initial}")

        await browser.close()

asyncio.run(debug_reddit())
EOF
```

This will show if scrolling triggers new content loading.
